
1. Sensors (Basel). 2021 Oct 27;21(21). pii: 7116. doi: 10.3390/s21217116.

Impact of Lung Segmentation on the Diagnosis and Explanation of COVID-19 in Chest
X-ray Images.

Teixeira LO(1), Pereira RM(2), Bertolini D(3), Oliveira LS(4), Nanni L(5),
Cavalcanti GDC(6), Costa YMG(1).

Author information: 
(1)Departamento de Informática, Universidade Estadual de Maringá, Maringá
87020-900, Brazil.
(2)Instituto Federal do Paraná, Pinhais 83330-200, Brazil.
(3)Departamento Acadêmico de Ciência da Computação, Universidade Tecnológica
Federal do Paraná, Campo Mourão 87301-899, Brazil.
(4)Departamento de Informática, Universidade Federal do Paraná, Curitiba
81531-980, Brazil.
(5)Dipartimento di Ingegneria dell'Informazione, Università degli Studi di
Padova, 35122 Padova, Italy.
(6)Centro de Informática, Universidade Federal de Pernambuco, Recife 50740-560,
Brazil.

COVID-19 frequently provokes pneumonia, which can be diagnosed using imaging
exams. Chest X-ray (CXR) is often useful because it is cheap, fast, widespread,
and uses less radiation. Here, we demonstrate the impact of lung segmentation in 
COVID-19 identification using CXR images and evaluate which contents of the image
influenced the most. Semantic segmentation was performed using a U-Net CNN
architecture, and the classification using three CNN architectures (VGG, ResNet, 
and Inception). Explainable Artificial Intelligence techniques were employed to
estimate the impact of segmentation. A three-classes database was composed: lung 
opacity (pneumonia), COVID-19, and normal. We assessed the impact of creating a
CXR image database from different sources, and the COVID-19 generalization from
one source to another. The segmentation achieved a Jaccard distance of 0.034 and 
a Dice coefficient of 0.982. The classification using segmented images achieved
an F1-Score of 0.88 for the multi-class setup, and 0.83 for COVID-19
identification. In the cross-dataset scenario, we obtained an F1-Score of 0.74
and an area under the ROC curve of 0.9 for COVID-19 identification using
segmented images. Experiments support the conclusion that even after
segmentation, there is a strong bias introduced by underlying factors from
different sources.

DOI: 10.3390/s21217116 
PMCID: PMC8587284
PMID: 34770423  [Indexed for MEDLINE]


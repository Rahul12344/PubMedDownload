
1. Int J Environ Res Public Health. 2021 Oct 21;18(21). pii: 11086. doi:
10.3390/ijerph182111086.

COVID-Transformer: Interpretable COVID-19 Detection Using Vision Transformer for 
Healthcare.

Shome D(1), Kar T(1), Mohanty SN(2), Tiwari P(3), Muhammad K(4), AlTameem A(5),
Zhang Y(6), Saudagar AKJ(5).

Author information: 
(1)School of Electronics Engineering, KIIT Deemed to be University, Odisha
751024, India.
(2)Department of Computer Science & Engineering, Vardhaman College of Engineering
(Autonomous), Hyderabad 501218, India.
(3)Department of Computer Science, Aalto University, 02150 Espoo, Finland.
(4)Visual Analytics for Knowledge Laboratory (VIS2KNOW Lab), Department of
Software, Sejong University, Seoul 143-747, Korea.
(5)Information Systems Department, College of Computer and Information Sciences, 
Imam Mohammad Ibn Saud Islamic University (IMSIU), Riyadh 11432, Saudi Arabia.
(6)Software Engineering College, Zhengzhou University of Light Industry,
Zhengzhou 450001, China.

In the recent pandemic, accurate and rapid testing of patients remained a
critical task in the diagnosis and control of COVID-19 disease spread in the
healthcare industry. Because of the sudden increase in cases, most countries have
faced scarcity and a low rate of testing. Chest X-rays have been shown in the
literature to be a potential source of testing for COVID-19 patients, but
manually checking X-ray reports is time-consuming and error-prone. Considering
these limitations and the advancements in data science, we proposed a Vision
Transformer-based deep learning pipeline for COVID-19 detection from chest
X-ray-based imaging. Due to the lack of large data sets, we collected data from
three open-source data sets of chest X-ray images and aggregated them to form a
30 K image data set, which is the largest publicly available collection of chest 
X-ray images in this domain to our knowledge. Our proposed transformer model
effectively differentiates COVID-19 from normal chest X-rays with an accuracy of 
98% along with an AUC score of 99% in the binary classification task. It
distinguishes COVID-19, normal, and pneumonia patient's X-rays with an accuracy
of 92% and AUC score of 98% in the Multi-class classification task. For
evaluation on our data set, we fine-tuned some of the widely used models in
literature, namely, EfficientNetB0, InceptionV3, Resnet50, MobileNetV3, Xception,
and DenseNet-121, as baselines. Our proposed transformer model outperformed them 
in terms of all metrics. In addition, a Grad-CAM based visualization is created
which makes our approach interpretable by radiologists and can be used to monitor
the progression of the disease in the affected lungs, assisting healthcare.

DOI: 10.3390/ijerph182111086 
PMCID: PMC8583247
PMID: 34769600  [Indexed for MEDLINE]

